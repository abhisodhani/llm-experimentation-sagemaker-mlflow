{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning and Evaluating LLMs with SageMaker Pipelines and MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker==2.225.0  datasets==2.18.0 transformers==4.40.0 mlflow==2.13.2 sagemaker-mlflow==0.1.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries and Setting Up Environment**\n",
    "\n",
    "This part imports all necessary Python modules. It includes SageMaker-specific imports for pipeline creation and execution, as well as user-defined functions for the pipeline steps like finetune_llama7b_hf and preprocess_llama3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.workflow.function_step import step\n",
    "from steps.finetune_llama7b_hf import finetune_llama7b\n",
    "from steps.preprocess_llama3 import preprocess\n",
    "from steps.evaluation_mlflow import evaluation\n",
    "from steps.utils import create_training_job_name\n",
    "import os\n",
    "\n",
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SageMaker Session and IAM Role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_execution_role()`: Retrieves the IAM role that SageMaker will use to access AWS resources. This role needs appropriate permissions for tasks like accessing S3 buckets and creating SageMaker resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "    print(role)\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    role = iam.get_role(RoleName=\"sagemaker_execution_role\")[\"Role\"][\"Arn\"]\n",
    "\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Configuration**\n",
    "\n",
    "The train_config dictionary is comprehensive, including:\n",
    "\n",
    "Experiment naming for tracking purposes\n",
    "Model specifications (ID, version, name)\n",
    "Infrastructure details (instance types and counts for fine-tuning and deployment)\n",
    "Training hyperparameters (epochs, batch size)\n",
    "\n",
    "This configuration allows for easy adjustment of the training process without changing the core pipeline code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = {\n",
    "    \"experiment_name\": \"all_target_modules_1K\",\n",
    "    \"model_id\": \"meta-llama/Meta-Llama-3-8B\",\n",
    "    \"model_version\": \"3.0.2\",\n",
    "    \"model_name\": \"llama-3-8b\",\n",
    "    \"endpoint_name\": \"llama-3-8b\",\n",
    "    \"finetune_instance_type\": \"ml.g5.12xlarge\",\n",
    "    \"finetune_num_instances\": 1,\n",
    "    \"instance_type\": \"ml.g5.12xlarge\",\n",
    "    \"num_instances\": 1,\n",
    "    \"epoch\": 1,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LoRA Parameters**\n",
    "\n",
    "Low-Rank Adaptation (LoRA) is an efficient fine-tuning technique for large language models. The parameters here (lora_r, lora_alpha, lora_dropout) control the behavior of LoRA during fine-tuning, affecting the trade-off between model performance and computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_params = {\"lora_r\": 8, \"lora_alpha\": 16, \"lora_dropout\": 0.05}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. MLflow Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLflow integration is crucial for experiment tracking and management.\n",
    "\n",
    "mlflow_arn: The ARN for the MLflow tracking server. You can get this ARN from SageMaker Studio UI. This allows the pipeline to log metrics, parameters, and artifacts to a central location.\n",
    "\n",
    "experiment_name: give appropriate name for experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_arn = \"<MLflow_tracking_server_ARN>\"  # fill MLflow tracking server ARN\n",
    "experiment_name = \"sm-pipelines-finetuning-eval\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Dataset Configuration\n",
    "\n",
    "For the purpose of fine tuning and evaluation we are going too use `HuggingFaceH4/no_robots` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"HuggingFaceH4/no_robots\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Pipeline Steps\n",
    "\n",
    "This section defines the core components of the SageMaker pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterString\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = ParameterString(name=\"lora_config\", default_value=json.dumps(lora_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing Step**\n",
    "\n",
    "This step handles data preparation. We are going to prepare data for training and evaluation. We will log this data in MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = \"fmops-training-evaulation-pipeline-mlflow\"\n",
    "\n",
    "default_bucket = sagemaker.Session().default_bucket()\n",
    "main_data_path = f\"s3://{default_bucket}\"\n",
    "evaluation_data_path = (\n",
    "    main_data_path\n",
    "    + \"/datasets/hf_no_robots/evaluation/automatic_small/dataset_evaluation_small.jsonl\"\n",
    ")\n",
    "output_data_path = main_data_path + \"/datasets/hf_no_robots/output_\" + pipeline_name\n",
    "\n",
    "# You can add your own evaluation dataset code into this step\n",
    "preprocess_step_ret = step(preprocess, name=\"preprocess\")(\n",
    "    default_bucket,\n",
    "    dataset_name,\n",
    "    train_sample=100,\n",
    "    eval_sample=100,\n",
    "    mlflow_arn=mlflow_arn,\n",
    "    experiment_name=experiment_name,\n",
    "    run_name=ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    ")\n",
    "\n",
    "print(\"The pipeline name is \" + pipeline_name)\n",
    "# Mark the name of this bucket for reviewing the artifacts generated by this pipeline at the end of the execution\n",
    "print(\"Output S3 bucket: \" + output_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine-tuning Step**\n",
    "\n",
    "This is where the actual model adaptation occurs. The step takes the preprocessed data and applies it to fine-tune the base LLM (in this case, a Llama model). It incorporates the LoRA technique for efficient adaptation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_ret = step(finetune_llama7b, name=\"finetune_llama8b_instruction\")(\n",
    "    preprocess_step_ret,\n",
    "    train_config,\n",
    "    lora_config,\n",
    "    role,\n",
    "    mlflow_arn,\n",
    "    experiment_name,\n",
    "    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Step**\n",
    "\n",
    "After fine-tuning, this step assesses the model's performance. It uses built-in evaluation function in MLflow to evaluate metrices like toxicity, exact_match etc:\n",
    "\n",
    "It will then log the results in MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_finetuned_llama7b_instruction_mlflow = step(\n",
    "    evaluation,\n",
    "    name=\"evaluate_finetuned_llama8b_instr\",\n",
    "    # keep_alive_period_in_seconds=1200,\n",
    "    instance_type=\"ml.g5.12xlarge\",\n",
    "    volume_size=100,\n",
    ")(train_config, preprocess_step_ret, finetune_ret, mlflow_arn, experiment_name, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Pipeline Creation and Execution\n",
    "\n",
    "This final section brings all the components together into an executable pipeline.\n",
    "\n",
    "**Creating the Pipeline**\n",
    "\n",
    "The pipeline object is created with all defined steps. The lora_config is passed as a parameter, allowing for easy modification of LoRA settings between runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    steps=[evaluate_finetuned_llama7b_instruction_mlflow],\n",
    "    parameters=[lora_config],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upserting the Pipeline**\n",
    "\n",
    "This step either creates a new pipeline in SageMaker or updates an existing one with the same name. It's a key part of the MLOps process, allowing for iterative refinement of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Starting the Pipeline Execution**\n",
    "\n",
    "This command kicks off the actual execution of the pipeline in SageMaker. From this point, SageMaker will orchestrate the execution of each step, managing resources and data flow between steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution1 = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets run another experiment with different LORA configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_params_2 = {\"lora_r\": 32, \"lora_alpha\": 64, \"lora_dropout\": 0.05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution2 = pipeline.start(\n",
    "    parameters={\n",
    "        \"lora_config\": json.dumps(lora_params_2),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "response = sagemaker_client.delete_pipeline(\n",
    "    PipelineName=pipeline_name,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
